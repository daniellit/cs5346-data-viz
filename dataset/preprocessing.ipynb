{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_19972\\3656949642.py:10: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gdelt_df = pd.read_csv(\"gdelt/GDELT_dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "fomc_df = pd.read_csv(\"FOMC_dataset.csv\")\n",
    "spx_df = pd.read_csv(\"^SPX_data.csv\")\n",
    "nasdaq100_df = pd.read_csv(\"^NDX_data.csv\")\n",
    "russell2000_df = pd.read_csv(\"^RUT_data.csv\")\n",
    "dowjones_df = pd.read_csv(\"^DJI_data.csv\")\n",
    "gdelt_df = pd.read_csv(\"gdelt/GDELT_dataset.csv\")\n",
    "cameo_df = pd.read_csv(\"gdelt/CAMEO_eventcodes.txt\", sep=\"\\t\")\n",
    "# Display the first few rows of each dataset to understand their structure\n",
    "# fomc_df.head(), spx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_changes(df):\n",
    "    # Explicitly convert 'Date' to datetime and handle errors\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    \n",
    "    # Drop rows where 'Date' is NaT after conversion\n",
    "    df = df.dropna(subset=['Date']).reset_index(drop=True)\n",
    "    \n",
    "    # Explicitly ensure 'Close' is numeric, handle errors\n",
    "    df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "    df = df.dropna(subset=['Close']).reset_index(drop=True)\n",
    "\n",
    "    # Ensure data is sorted\n",
    "    df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "    # Calculate Daily Close Change %\n",
    "    df['Daily Close Chg%'] = df['Close'].pct_change() * 100\n",
    "\n",
    "    # Monthly Close Change % (last close of previous month vs last close of current month)\n",
    "    df['Month'] = df['Date'].dt.to_period('M')\n",
    "    # Get the last close of each month\n",
    "    last_monthly_close = df.groupby('Month')['Close'].last()\n",
    "    # Map last close to each row and shift to get previous month's last close\n",
    "    df['Prev Month Last Close'] = df['Month'].map(last_monthly_close).shift(1)\n",
    "    # Current month's last close for each row\n",
    "    df['Current Month Last Close'] = df['Month'].map(last_monthly_close)\n",
    "    # Calculate monthly change\n",
    "    monthly_chg = (df['Current Month Last Close'] - df['Prev Month Last Close']) / df['Prev Month Last Close'] * 100\n",
    "    # Only record on the last day of each month\n",
    "    df['Monthly Close Chg%'] = monthly_chg.where(df['Date'].dt.is_month_end, other=float('nan'))\n",
    "\n",
    "    # Yearly Close Change % (last close of previous year vs last close of current year)\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    # Get the last close of each year\n",
    "    last_yearly_close = df.groupby('Year')['Close'].last()\n",
    "    # Map last close to each row and shift to get previous year's last close\n",
    "    df['Prev Year Last Close'] = df['Year'].map(last_yearly_close).shift(1)\n",
    "    # Current year's last close for each row\n",
    "    df['Current Year Last Close'] = df['Year'].map(last_yearly_close)\n",
    "    # Calculate yearly change\n",
    "    yearly_chg = (df['Current Year Last Close'] - df['Prev Year Last Close']) / df['Prev Year Last Close'] * 100\n",
    "    # Only record on the last day of each year\n",
    "    df['Year Close Chg%'] = yearly_chg.where(df['Date'].dt.is_year_end, other=float('nan'))\n",
    "\n",
    "    # Drop helper columns\n",
    "    df.drop(columns=['Month', 'Year', 'Prev Month Last Close', 'Current Month Last Close', \n",
    "                     'Prev Year Last Close', 'Current Year Last Close'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAMEOEVENTCODE      0\n",
       "EVENTDESCRIPTION    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cameo_df.head()\n",
    "# check for missing values in cameo_df\n",
    "cameo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>EventCode</th>\n",
       "      <th>event_count</th>\n",
       "      <th>average_tone</th>\n",
       "      <th>average_goldstein</th>\n",
       "      <th>total_mentions</th>\n",
       "      <th>total_sources</th>\n",
       "      <th>total_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>144</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.697527</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>195</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.151181</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>22</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>193</td>\n",
       "      <td>598</td>\n",
       "      <td>-5.894597</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>2752</td>\n",
       "      <td>619</td>\n",
       "      <td>2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>043</td>\n",
       "      <td>2450</td>\n",
       "      <td>-0.541621</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10865</td>\n",
       "      <td>2518</td>\n",
       "      <td>10598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>154</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.224078</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date EventCode  event_count  average_tone  average_goldstein  \\\n",
       "0  2024-12-31       144            5     -2.697527               -7.5   \n",
       "1  2024-12-31       195           20     -6.151181              -10.0   \n",
       "2  2024-12-31       193          598     -5.894597              -10.0   \n",
       "3  2024-12-31       043         2450     -0.541621                2.8   \n",
       "4  2024-12-31       154           18     -1.224078               -7.2   \n",
       "\n",
       "   total_mentions  total_sources  total_articles  \n",
       "0              35              5              35  \n",
       "1             102             22             102  \n",
       "2            2752            619            2657  \n",
       "3           10865           2518           10598  \n",
       "4             114             18             114  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 676092 entries, 0 to 676091\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   event_date         676092 non-null  object \n",
      " 1   EventCode          676092 non-null  object \n",
      " 2   event_count        676092 non-null  int64  \n",
      " 3   average_tone       676092 non-null  float64\n",
      " 4   average_goldstein  675650 non-null  float64\n",
      " 5   total_mentions     676092 non-null  int64  \n",
      " 6   total_sources      676092 non-null  int64  \n",
      " 7   total_articles     676092 non-null  int64  \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 41.3+ MB\n"
     ]
    }
   ],
   "source": [
    "gdelt_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 675650 entries, 0 to 676091\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   event_date         675650 non-null  datetime64[ns]\n",
      " 1   EventCode          675650 non-null  object        \n",
      " 2   event_count        675650 non-null  int64         \n",
      " 3   average_tone       675650 non-null  float64       \n",
      " 4   average_goldstein  675650 non-null  float64       \n",
      " 5   total_mentions     675650 non-null  int64         \n",
      " 6   total_sources      675650 non-null  int64         \n",
      " 7   total_articles     675650 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(1)\n",
      "memory usage: 46.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# remove null values in average_goldstein\n",
    "gdelt_df['event_date'] = pd.to_datetime(gdelt_df['event_date'])\n",
    "gdelt_df = gdelt_df[gdelt_df['average_goldstein'].notnull()]\n",
    "gdelt_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Date                    0\n",
      "Unnamed: 0              0\n",
      "CPI                     0\n",
      "Industry Production     0\n",
      "PCE                     0\n",
      "                       ..\n",
      "Unemployment Lag_12     0\n",
      "Wage Increase Lag_12    0\n",
      "Home Sales Lag_12       0\n",
      "Retail Trade Lag_12     0\n",
      "Real GDP Lag_12         0\n",
      "Length: 102, dtype: int64\n",
      "Final Columns: ['Date', 'Year', 'Month', 'CPI', 'Unemployment', 'Fed Rate', 'Real GDP', 'Inflation', 'Home Sales', 'Retail Sales', 'Industry Production Lag_1', 'Unemployment Lag_1', 'YoY Unemployment', 'Month_Sin', 'Month_Cos']\n"
     ]
    }
   ],
   "source": [
    "# Convert Date columns to datetime format\n",
    "fomc_df['Date'] = pd.to_datetime(fomc_df['Date'])\n",
    "fomc_df['Year'] = fomc_df['Date'].dt.year\n",
    "fomc_df['Month'] = fomc_df['Date'].dt.month\n",
    "spx_df = spx_df.iloc[2:].reset_index(drop=True)  # Remove metadata rows\n",
    "nasdaq100_df = nasdaq100_df.iloc[2:].reset_index(drop=True)\n",
    "russell2000_df = russell2000_df.iloc[2:].reset_index(drop=True)\n",
    "djia_df = dowjones_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "spx_df.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Name']\n",
    "spx_df = spx_df.drop(columns=['Name'])  # Remove unnecessary column\n",
    "nasdaq100_df.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Name']\n",
    "nasdaq100_df = nasdaq100_df.drop(columns=['Name'])\n",
    "russell2000_df.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Name']\n",
    "russell2000_df = russell2000_df.drop(columns=['Name'])\n",
    "djia_df.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Name']\n",
    "djia_df = djia_df.drop(columns=['Name'])\n",
    "\n",
    "# Convert numeric columns to float type\n",
    "numeric_cols = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "spx_df[numeric_cols] = spx_df[numeric_cols].astype(float)\n",
    "nasdaq100_df[numeric_cols] = nasdaq100_df[numeric_cols].astype(float)\n",
    "russell2000_df[numeric_cols] = russell2000_df[numeric_cols].astype(float)\n",
    "djia_df[numeric_cols] = djia_df[numeric_cols].astype(float)\n",
    "\n",
    "# Remove records before a certain cutoff date\n",
    "cutoff_date = pd.to_datetime(\"2013-01-01\")\n",
    "fomc_df = fomc_df[fomc_df['Date'] >= cutoff_date]\n",
    "\n",
    "# Group by Date and aggregate\n",
    "numeric_cols = fomc_df.select_dtypes(include=[np.number]).columns.drop('FOMC Meeting', errors='ignore') \n",
    "fomc_df = fomc_df.groupby('Date')[numeric_cols].mean().reset_index()\n",
    "\n",
    "# Fill missing FOMC Meeting with 0 (no meeting)\n",
    "print(\"Missing Values:\\n\", fomc_df.isnull().sum())\n",
    "\n",
    "# Cell 6: Treat Outliers\n",
    "fomc_df['Real GDP'] = fomc_df['Real GDP'].replace(28630.739, np.nan)\n",
    "fomc_df['Real GDP'] = fomc_df['Real GDP'].interpolate(method='linear')\n",
    "fomc_df['Home Sales'] = fomc_df['Home Sales'].clip(lower=400, upper=800) \n",
    "\n",
    "# Cell 8: Select Key Columns for Tableau\n",
    "key_columns = [\n",
    "    'Date', 'Year', 'Month', 'CPI', 'Unemployment', 'Fed Rate', 'Real GDP', \n",
    "    'Inflation', 'Home Sales', 'Retail Sales', 'FOMC Meeting', 'Regime',\n",
    "    'Industry Production Lag_1', 'Unemployment Lag_1', 'YoY CPI', 'YoY Unemployment',\n",
    "    'Month_Sin', 'Month_Cos'\n",
    "]\n",
    "\n",
    "fomc_df = fomc_df[[col for col in key_columns if col in fomc_df.columns]]\n",
    "print(\"Final Columns:\", fomc_df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_df = calculate_changes(spx_df)\n",
    "nasdaq100_df = calculate_changes(nasdaq100_df)\n",
    "russell2000_df = calculate_changes(russell2000_df)\n",
    "djia_df = calculate_changes(djia_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc_df.to_csv(\"FOMC_dataset_cleaned.csv\", index=False)\n",
    "spx_df.to_csv(\"SPX_dataset_cleaned.csv\", index=False)\n",
    "nasdaq100_df.to_csv(\"NDX_dataset_cleaned.csv\", index=False)\n",
    "russell2000_df.to_csv(\"RUT_dataset_cleaned.csv\", index=False)\n",
    "djia_df.to_csv(\"DJI_dataset_cleaned.csv\", index=False)\n",
    "gdelt_df.to_csv(\"GDELT_dataset_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
